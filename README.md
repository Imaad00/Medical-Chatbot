# ğŸ©º Medical Chatbot with HuggingFace, FAISS, and Mistral

This project demonstrates how to build a **smart Medical Chatbot** using open-source tools.  
It leverages:

- **HuggingFace** â†’ For embeddings and LLM access  
- **FAISS (CPU)** â†’ For fast vector similarity search  
- **LangChain** â†’ For orchestration and memory management  
- **Streamlit** â†’ For a simple web-based conversational interface  
- **Mistral** â†’ As the large language model for chatbot responses  

The chatbot can read and understand medical documents (e.g., *The Gale Encyclopedia of Medicine*) and answer user queries conversationally.  

---

## ğŸ“‚ Project Structure

```bash
â”œâ”€â”€ Pipfile
â”œâ”€â”€ Pipfile.lock
â”œâ”€â”€ README.md
â”œâ”€â”€ connect_memory_with_llm.py
â”œâ”€â”€ create_memory_for_llm.py
â”œâ”€â”€ data
â”‚   â””â”€â”€ The_GALE_ENCYCLOPEDIA_of_MEDICINE_SECOND.pdf
â”œâ”€â”€ medibot.py
â”œâ”€â”€ medical-chatbot-ppt.pdf
â”œâ”€â”€ requirements.txt
â””â”€â”€ vectorstore
    â””â”€â”€ db_faiss
        â”œâ”€â”€ index.faiss
        â””â”€â”€ index.pkl

- data/ â†’ Contains medical knowledge base (PDFs).  
- vectorstore/ â†’ Stores FAISS vector indexes for retrieval.  
- create_memory_for_llm.py â†’ Preprocesses documents and builds the vector store.  
- connect_memory_with_llm.py â†’ Connects embeddings with the LLM.  
- medibot.py â†’ Main chatbot app powered by Streamlit.  
- requirements.txt â†’ Dependencies for pip.  
- Pipfile / Pipfile.lock â†’ Environment management with Pipenv.  

```
## ğŸ”‘ Environment Variables

Before running the chatbot, make sure you set the following environment variables:

- **`HF_TOKEN`** â†’ Your Hugging Face access token (used for embeddings/models).  
- **`GROQ_API_KEY`** â†’ Your Groq API key (used for running the Mistral model).  

### 1. Create a `.env` file

In the root of your project, create a file named `.env`:

```bash
HF_TOKEN=your_huggingface_token_here
GROQ_API_KEY=your_groq_api_key_here
```

## ğŸš€ Getting Started

### 1. Prerequisites

- Python 3.9+  
- [Pipenv](https://pipenv.pypa.io/en/latest/) installed on your system  

Install Pipenv (if not already installed):

```bash
pip install pipenv
```

### 2. Set Up the Environment

Navigate to the project directory and install dependencies:

```bash
pipenv install langchain langchain_community langchain_huggingface faiss-cpu pypdf
pipenv install huggingface_hub
pipenv install streamlit

Alternatively, install dependencies via `requirements.txt`:

pip install -r requirements.txt
```
### 3. Prepare the Knowledge Base

Process the medical PDF and create a FAISS vector index:

```bash
pipenv run python create_memory_for_llm.py

This will generate embeddings and store them in:

vectorstore/db_faiss/
```
### 4. Launch the Chatbot

Start the Streamlit application:

```bash
pipenv run streamlit run medibot.py
```

## âš™ï¸ How It Works

1. **Document Ingestion** â†’ PDFs from `data/` are read and chunked.  
2. **Embeddings** â†’ Text chunks are embedded using HuggingFace models.  
3. **Vector Store** â†’ Embeddings are indexed in FAISS for efficient retrieval.  
4. **Retrieval + LLM** â†’ Relevant chunks are retrieved and passed to the Mistral LLM.  
5. **Conversational Interface** â†’ Streamlit provides a user-friendly chat interface.  

